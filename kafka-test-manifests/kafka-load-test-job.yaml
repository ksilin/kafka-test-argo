apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-load-test-with-results
  namespace: kafka-test
spec:
  ttlSecondsAfterFinished: 86400  # Keep job for 1 day after completion
  template:
    spec:
      containers:
      - name: kafka-test
        image: ghcr.io/ksilin/kafka-autotest:0.0.2
        imagePullPolicy: Always
        command: ["/bin/bash"]
        args:
        - "-c"
        - |
          # Change to home directory to ensure consistent location
          cd /home/appuser
          
          # Create a summary file
          SUMMARY_FILE="/results/load_test_summary.txt"
          touch $SUMMARY_FILE
          
          # Run the test script and capture output
          echo "Running Kafka load test..." | tee -a $SUMMARY_FILE
          echo "=======================================" | tee -a $SUMMARY_FILE
          /usr/local/bin/kafka-test.sh --mode load \
            --config /config/client.properties \
            --topic load-test-$POD_UID \
            --producers 3 \
            --steps 4 \
            --latency 2000 \
            --max-messages 1000000 \
            --verbose | tee -a $SUMMARY_FILE
          
          # Find results directory
          RESULTS_DIRS=$(find /home/appuser -type d -name "kafka_test_*" | sort -r | head -1)
          echo "=======================================" | tee -a $SUMMARY_FILE
          echo "Test results found in: $RESULTS_DIRS" | tee -a $SUMMARY_FILE
          echo "Copying results to /results directory..." | tee -a $SUMMARY_FILE
          
          # Create subdirectories for each producer output
          mkdir -p /results/producer_outputs
          
          # Copy result files to the /results directory
          find "$RESULTS_DIRS" -type f -name "*.csv" -exec cp -v {} /results/ \; | tee -a $SUMMARY_FILE
          find "$RESULTS_DIRS" -type f -name "producer_*.txt" -exec cp -v {} /results/producer_outputs/ \; | tee -a $SUMMARY_FILE
          
          # Copy any other txt/csv files in the current directory
          find /home/appuser -maxdepth 1 -name "*.txt" -o -name "*.csv" -exec cp -v {} /results/ \; | tee -a $SUMMARY_FILE
          
          # Create a detailed summary of result files
          echo "=======================================" | tee -a $SUMMARY_FILE
          echo "Files available in /results:" | tee -a $SUMMARY_FILE
          ls -la /results | tee -a $SUMMARY_FILE
          
          echo "Producer output files:" | tee -a $SUMMARY_FILE
          ls -la /results/producer_outputs | tee -a $SUMMARY_FILE
          
          # For each CSV file, add a preview to the summary
          echo "=======================================" | tee -a $SUMMARY_FILE
          echo "CSV Results:" | tee -a $SUMMARY_FILE
          for file in $(find /results -maxdepth 1 -name "*.csv"); do
            echo "" | tee -a $SUMMARY_FILE
            echo "File: $file" | tee -a $SUMMARY_FILE
            echo "-------------------" | tee -a $SUMMARY_FILE
            head -n 20 $file | tee -a $SUMMARY_FILE
            echo "..." | tee -a $SUMMARY_FILE
          done
          
          # Keep container running for result inspection
          echo "Test completed. Container will stay alive for 1 hour for result inspection."
          echo "Access results with: kubectl exec -it $(hostname) -n kafka-test -- ls -la /results"
          echo "View summary with: kubectl exec -it $(hostname) -n kafka-test -- cat /results/load_test_summary.txt"
          sleep 3600
        volumeMounts:
        - name: config-volume
          mountPath: /config
        - name: truststore-volume
          mountPath: /certs
        - name: results-volume
          mountPath: /results
        env:
        - name: POD_UID
          valueFrom:
            fieldRef:
              fieldPath: metadata.uid
      volumes:
      - name: config-volume
        configMap:
          name: kafka-client-properties
      - name: truststore-volume
        secret:
          secretName: kafka-truststore
      - name: results-volume
        emptyDir: {}
      restartPolicy: Never
  backoffLimit: 2